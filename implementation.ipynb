{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust detrending, rereferencing, outlier detection, and inpainting, for-multichannel-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of [1] in Python and experiments on real time series.  \n",
    "Esteban Christiann (ENS Paris-Saclay) and Alexi Canesse (ENS de Lyon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, lfilter\n",
    "from meegkit.utils.sig import stmcb # Steiglitz-McBride iteration method for ringing removal\n",
    "from alphacsc import learn_d_z\n",
    "try:\n",
    "    from alphacsc.utils import construct_X\n",
    "except:\n",
    "    from alphacsc.utils.convolution import construct_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "Load MEG data extracted from [2] *(See the end of the notebook for the data extraction)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cool_channels = [3, 12, 15, 19, 22]\n",
    "FS = 2400 # Sampling frequency = 2400Hz\n",
    "\n",
    "meg_data = np.load(\"data/MEG.npy\")\n",
    "\n",
    "print(meg_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three channel synthetic data with linear dependancy (according to model 2 in [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 300\n",
    "t, x1, _ = utils.generate_noisy_polynomial(degree=10, noise_level=0.2, num_points=num_points)\n",
    "_, x2, _ = utils.generate_noisy_polynomial(degree=10, noise_level=0.2, num_points=num_points)\n",
    "x3 = x1 + x2 + np.random.normal(scale=0.2, size=[num_points])\n",
    "x = np.stack([x1, x2, x3], axis=1)\n",
    "x_not_corrupted = x.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add some corruption to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.ones([num_points, 3], dtype=bool)\n",
    "w[50:75, 0] = False\n",
    "w[100:150, 1] = False\n",
    "w[200:220, 2] = False\n",
    "x[~w] = 10\n",
    "x1, x2, x3 = x.T\n",
    "\n",
    "utils.plot_signals_side_by_side(t, x.T, x_not_corrupted.T, y_names1=[\"x1\", \"x2\", \"x3\"], y_names2=[\"x1\", \"x2\", \"x3\"], title1=\"Corruped signal\", title2=\"Not corrupted signal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synthetic data with steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data with steps \n",
    "sigma = 1e-1\n",
    "x_step = np.random.randn(3, num_points) * sigma\n",
    "# Add steps\n",
    "for signal in x_step:\n",
    "    step_locations = utils.generate_random_numbers(np.random.randint(3, 10), 10, num_points - 9, 15)\n",
    "    for step_location in step_locations:\n",
    "        signal[step_location:] += 1. + np.random.random()\n",
    "utils.plot_signals(t, x_step, title=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Robust detrending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_detrend(x, order, w=None, basis='polynomials', thresh=0.5, maxiter=20):\n",
    "     \"\"\"\n",
    "     Robustly removes trend from data.\n",
    "\n",
    "     Parameters:\n",
    "     - x: raw data\n",
    "     - order: order of polynomial or number of sin/cosine pairs\n",
    "     - w: weights\n",
    "     - basis: 'polynomials' [default] or 'sinusoids', or user-provided matrix\n",
    "     - thresh: threshold for outliers [default: .5 sd]\n",
    "     - maxiter: number of iterations [default: 20]\n",
    "\n",
    "     Returns:\n",
    "     - original - trend: detrended data\n",
    "     - trend: trend\n",
    "     - w: updated weights\n",
    "     - r: basis matrix used\n",
    "     \"\"\"\n",
    "     # Generate basis matrix\n",
    "     if isinstance(basis, np.ndarray):\n",
    "          r = basis\n",
    "     else:\n",
    "          lin = np.linspace(-1, 1, x.shape[0])\n",
    "          if basis == 'polynomials':\n",
    "               r = np.column_stack([lin ** k for k in range(0, order + 1)])\n",
    "          elif basis == 'sinusoids':\n",
    "               r = np.column_stack([np.sin(2 * np.pi * k * lin / 2) for k in range(0, order + 1)] +\n",
    "                                   [np.cos(2 * np.pi * k * lin / 2) for k in range(0, order + 1)])\n",
    "          else:\n",
    "               raise ValueError(\"Invalid basis type\")\n",
    "\n",
    "     # Initialize weights if not provided\n",
    "     if w is None:\n",
    "          if len(x.shape) == 1:\n",
    "               w = np.ones_like(x, dtype=bool)[:, np.newaxis]\n",
    "          else:\n",
    "               w = np.ones_like(x, dtype=bool)[:]\n",
    "     \n",
    "     # If the data is multichannel, the algorithm is applied to each channel independently \n",
    "     trend = x.copy()\n",
    "     original = x.copy()\n",
    "     if len(trend.shape) == 1:\n",
    "          trend = trend[:, np.newaxis]\n",
    "          original = original[:, np.newaxis]\n",
    "     for _ in range(maxiter):\n",
    "          # If the data is multichannel, the algorithm is applied to each channel independently \n",
    "          for dim in range(trend.shape[1]):\n",
    "               # Fit to basis\n",
    "               coefficients, _, _, _ = np.linalg.lstsq(r[w[:, dim],:], original[w[:, dim], dim], rcond=None)\n",
    "               trend[:,dim] = r @ coefficients\n",
    "               # Update weights\n",
    "               d = np.abs(trend[:, dim] - original[:, dim])\n",
    "\n",
    "               new_w = d < thresh * np.std(d)\n",
    "               if (new_w == w[:, dim]).all():\n",
    "                    # Algorithm converged, early stopping\n",
    "                    break\n",
    "               w[:, dim] = new_w\n",
    "\n",
    "\n",
    "     return original - trend, trend, w, r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the algorithm on our generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detrended_x1, trend_x1, weights_x1, _ = robust_detrend(x1, 10, thresh=1)\n",
    "utils.plot_signals(t, [x1, detrended_x1[:, 0], weights_x1, trend_x1], y_names=[\"signal\", \"detrended\", \"weights\", \"fit\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the algorithm on real MEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meg_chan = meg_data[:, 22]\n",
    "detrended_meg, trend_meg, _, _ = robust_detrend(meg_chan, 10, thresh=1)\n",
    "utils.plot_signals_side_by_side(np.arange(meg_chan.shape[0]), [meg_chan, trend_meg], [detrended_meg[:, 0]], y_names1=[\"signal\", \"fit\"], y_names2=[\"detrended\"], alpha1=[.75, .2, 1.], sharey=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meg_chan = meg_data[:, 3]\n",
    "detrended_meg, trend_meg, _, _ = robust_detrend(meg_chan, 10, thresh=1)\n",
    "utils.plot_signals_side_by_side(np.arange(meg_chan.shape[0]), [meg_chan, trend_meg], [detrended_meg[:, 0]], y_names1=[\"signal\", \"fit\"], y_names2=[\"detrended\"], alpha1=[.75, .2, 1.], sharey=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inpainting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from time import time\n",
    "import pandas as pd\n",
    "def inpaint(x, w, keep_valid=True):\n",
    "    \"\"\"\n",
    "    Reconstruct data if corrupted samples are known\n",
    "\n",
    "    Parameters:\n",
    "    - x: Nchannels x Nsamples raw data\n",
    "    - w: Nchannels x Nsamples bool matrix indicating corruptions\n",
    "    - keep_valid: set to true to reconstruct only corrupted samples\n",
    "\n",
    "    Returns:\n",
    "    - new_x: reconstructed data\n",
    "    \"\"\"\n",
    "    print('init')\n",
    "    ttt = time()\n",
    "    if w is None:\n",
    "        w = np.ones_like(x, dtype=bool)\n",
    "\n",
    "    N = x.shape[1] # Number of channels\n",
    "    new_x = x.copy()\n",
    "\n",
    "    for n in range(N):\n",
    "        print(f'copy {time()-ttt}')\n",
    "        ttt=time()\n",
    "        w_other = w.copy()\n",
    "        w_other[:, n] = False\n",
    "\n",
    "        # Partition the time axis using the state of other channels\n",
    "        print(f'unique {time()-ttt}')\n",
    "        ttt=time()\n",
    "        pattern, partition = np.unique(w_other, axis=0, return_inverse=True)\n",
    "        pattern = pd.unique(w_other)\n",
    "        K = pattern.shape[0]\n",
    "        print(f'unique2 {time()-ttt}')\n",
    "        ttt=time()\n",
    "\n",
    "        for k in tqdm(range(K)):\n",
    "\n",
    "            print(f'part {time()-ttt}')\n",
    "            ttt=time()\n",
    "            T_k = partition == k\n",
    "            Tprime_k = np.logical_and(w[:, n], T_k) # Timestamps we use to estimate the projection\n",
    "            \n",
    "            Tinpaint = np.logical_and(~w[:, n], T_k) # Timestamps to reconstruct\n",
    "            if not keep_valid:\n",
    "                Tinpaint = T_k\n",
    "\n",
    "            if Tinpaint.any():\n",
    "                print(f'cat {time()-ttt}')\n",
    "                ttt=time()\n",
    "                xn = x[:, n]\n",
    "                xother = x[:, pattern[k]]\n",
    "                xother = np.concatenate([xother, np.ones_like(xn)[:, None]], axis=1)\n",
    "\n",
    "                # Estimate the coefficients and reconstuct the data\n",
    "                print(f'est {time()-ttt}')\n",
    "                ttt=time()\n",
    "                coefs = np.linalg.lstsq(xother[Tprime_k], xn[Tprime_k], rcond=None)[0]\n",
    "                print(f'reconstruct {time()-ttt}')\n",
    "                ttt=time()\n",
    "                new_x[Tinpaint, n] = xother[Tinpaint] @ coefs\n",
    "\n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inpaint = inpaint(x, w)\n",
    "\n",
    "utils.plot_signals_side_by_side(t, x_inpaint.T, x.T, title1=\"Inpainted\", title2=\"Original\")\n",
    "\n",
    "to_plot = np.concatenate([x_inpaint, x_inpaint[:, [0]] + x_inpaint[:, [1]]], axis=1)\n",
    "utils.plot_signals_side_by_side(t, to_plot.T, [x_inpaint[:, 0] + x_inpaint[:, 1] - x_not_corrupted[:,2], x[:,2]], y_names1=[\"x1\", \"x2\", \"x3\", \"x1 + x2\"], y_names2=[\"Difference between not corrupted and reconstructed\", \"Corrupted\"], title1=\"Reconstruction of x3 using inpainted signals\", title2=\"Reconstruction of x3 using inpainted signals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_detection(x, thres=2., maxiter=20):\n",
    "    \"\"\"\n",
    "    Flag outliers using the inpaint algorithm\n",
    "\n",
    "    Parameters:\n",
    "    - x: Nchannels x Nsamples raw data\n",
    "    - thres: threshold for outlier detection (default: 2 stddev)\n",
    "    - maxiter: maximum number of iterations\n",
    "\n",
    "    Returns:\n",
    "    - w: Nchannels x Nsamples bool matrix where False indicates an outlier\n",
    "    \"\"\"\n",
    "    w = np.ones_like(x, dtype=bool) # Initially assume there are no outliers\n",
    "\n",
    "    for _ in range(maxiter):\n",
    "        # Try to reconstruct the data using the inpainting algorithm\n",
    "        xbar = inpaint(x, w, keep_valid=False)\n",
    "\n",
    "        # Flag high reconstruction errors as outliers\n",
    "        d = np.abs(x - xbar)\n",
    "        new_w = ~(d > thres * d.std(axis=0, keepdims=True))\n",
    "        \n",
    "        # Early stopping if the algorithm has converged\n",
    "        if (w == new_w).all():\n",
    "            return w\n",
    "        w = new_w\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_w = outlier_detection(x)\n",
    "utils.plot_signals_side_by_side(t, x.T, estimated_w.T, title1=\"Signal\", title2=\"estimated weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Robust Rereferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_rereferencing(x, w=None):\n",
    "    \"\"\"\n",
    "    Perform robust referencing on the input signal.\n",
    "\n",
    "    Parameters:\n",
    "    - x (numpy.ndarray): Input signal.\n",
    "    - w (numpy.ndarray): Weights from outlier detection.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: Robustly referenced signal.\n",
    "    \"\"\"\n",
    "    if w is None:\n",
    "        w = outlier_detection(x)\n",
    "    robust_mean = np.mean(x, where=w)\n",
    "    return x - robust_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying it on our generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rereferenced_x = robust_rereferencing(x)\n",
    "utils.plot_signals_side_by_side(t, rereferenced_x.T, rereferenced_x.T - (x_not_corrupted.T - np.mean(x_not_corrupted)), title1=\"Rereferenced\", title2=\"Difference with non corrupted rereferenced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Step Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_steps(x, thresh, guard, depth):\n",
    "    \"\"\"\n",
    "    Find step glitch\n",
    "\n",
    "    Parameters:\n",
    "    - x (numpy.ndarray): Data to clean.\n",
    "    - thresh (float): Threshold\n",
    "    - guard (int): Minimum duration of stable interval in samples .\n",
    "    - depth (int): Recursion depth, determines the number of steps.\n",
    "\n",
    "    Returns:\n",
    "    - stepList (list): Indices of steps.\n",
    "    \"\"\"\n",
    "    if depth == 0 or x.shape[0] <= 2 * guard:\n",
    "        return []\n",
    "\n",
    "    T = x.shape[0] # x is a single channel here\n",
    "\n",
    "    M0 = np.cumsum(x) / np.arange(1, T+1)\n",
    "    V0 = np.cumsum(np.square(x)) / np.arange(1, T+1)\n",
    "    V0 -= np.square(M0)\n",
    "    V0 *= np.arange(1, T+1)\n",
    "\n",
    "    MT = np.cumsum(x[::-1]) / np.arange(1, T+1)\n",
    "    VT = np.cumsum(np.square(x[::-1])) / np.arange(1, T+1)\n",
    "    VT -= np.square(MT)\n",
    "    VT *= np.arange(1, T+1)\n",
    "    VT = VT[::-1]\n",
    "    \n",
    "    t0 = np.argmin((V0 + VT)[guard : T-guard])\n",
    "    steps = [guard + t0]\n",
    "    \n",
    "    # Check if the step is relevent \n",
    "    if (V0[t0] + VT[t0]) / V0[-1] > thresh:\n",
    "        return []\n",
    "\n",
    "    if depth and steps:\n",
    "        steps_left = find_steps(x[:steps[0]], thresh=thresh, guard=guard, depth=depth-1)\n",
    "        # Add an offset because x[steps[0] + 1] becomes index 0\n",
    "        steps_right = steps[0] + find_steps(x[steps[0]+1:], thresh=thresh, guard=guard, depth=depth-1)\n",
    "        steps = np.concatenate((steps_left, steps, steps_right))\n",
    "\n",
    "    return steps.astype(int)\n",
    "\n",
    "def step_removal(x, thresh=0.7, guard=5, depth=5):\n",
    "    \"\"\"\n",
    "    Remove step glitch\n",
    "    \n",
    "    Parameters:\n",
    "    - x (numpy.ndarray): Data to clean (time * channels).\n",
    "    - thresh (float): Threshold (default: 0.7).\n",
    "    - guard (int): Minimum duration of stable interval in samples (default: 5).\n",
    "    - depth (int): Recursion depth (default: 5), determines the number of steps.\n",
    "\n",
    "    Returns:\n",
    "    - y (numpy.ndarray): Step-removed data.\n",
    "    - stepList (list): Indices of steps.\n",
    "    \"\"\"\n",
    "\n",
    "    y = x.copy()\n",
    "\n",
    "    all_stepList = []\n",
    "    for chan in range(x.shape[1]):\n",
    "        # Find step indices\n",
    "        stepList = find_steps(x[:, chan], thresh=thresh, guard=guard, depth=depth)\n",
    "\n",
    "        all_stepList.append(stepList)\n",
    "\n",
    "        if len(stepList):\n",
    "            stepList = [0] + list(stepList) + [x.shape[0]]\n",
    "            for split in range(1, len(stepList) - 1):\n",
    "                y1 = y[stepList[split - 1] + 1 : stepList[split] - 1, chan]  # plateau before\n",
    "                y2 = y[stepList[split] + 1 : stepList[split + 1] - 1, chan]  # plateau after\n",
    "                step = np.mean(y2) - np.mean(y1)\n",
    "                y[stepList[split] + 1:, chan] -= step\n",
    "\n",
    "    return y, np.array(all_stepList, dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the algorithm on our generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_step_removed, stepList = step_removal(x_step[[1]].T, thresh=0.7)\n",
    "utils.plot_signals(t, [x_step[[1]].T, x_step_removed], y_names=[\"Step signal\", \"de-stepped signal\"], y_lines=[t[step] for steps in stepList for step in steps])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the algorithm on real MEG data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that steps are removed but ringing still present..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meg_chan = meg_data[:, [19]]\n",
    "meg_nostep, step_list = step_removal(meg_chan)\n",
    "utils.plot_signals_side_by_side(range(meg_data.shape[0]), y1=[meg_chan, meg_nostep], y2=[meg_nostep], y_names1=[\"Step signal\", \"de-stepped signal\"], y_names2=\"de-stepped signal\", title1=\"Signal de de-step\", title2=\"de-stepped signal\", sharey=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ringing removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ringing_removal(x, step_list):\n",
    "    \"\"\"\n",
    "    Reduce ringing effect caused by the antialiasing filter response to steps\n",
    "\n",
    "    Paramters:\n",
    "    - x: (Nsamples, Nchannels) data matrix\n",
    "    - step_list: list of step indexes (can be found with step removal algorithm)\n",
    "\n",
    "    Return:\n",
    "    - new_x: cleaned data\n",
    "    \"\"\"\n",
    "    N = x.shape[1]\n",
    "    n_num, n_den = 8, 8\n",
    "    n_samples = 100\n",
    "\n",
    "    new_x = x.copy()\n",
    "    for n in range(N):\n",
    "        for step in step_list[n]:\n",
    "            ringing = x[step : step+n_samples, n]\n",
    "            ringing = ringing - ringing.mean()\n",
    "            if ringing.shape[0] < n_samples:\n",
    "                break\n",
    "            ringing[n_samples//2 : ] = 0\n",
    "            b, a = stmcb(ringing, q=n_num, p=n_den, niter=10)\n",
    "\n",
    "            impulse = np.arange(n_samples) == 0\n",
    "            model = lfilter(b, a, impulse)\n",
    "            new_x[step : step+n_samples, n] -= model\n",
    "\n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the algorithm on our generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some filter\n",
    "[b, a] = butter(6, 0.2)\n",
    "\n",
    "x = np.arange(300) == 0 # An impulse...\n",
    "x = lfilter(b, a, x) * 100 # ... goes through the filter\n",
    "x = np.roll(x, 50) + np.random.normal(size=300)\n",
    "x = x[:, None]\n",
    "t = np.linspace(0, 1, x.shape[0])\n",
    "\n",
    "# We already kown that the problem is at timestep 50, but with real data we would\n",
    "# get the timesteps from the step removal algorithm\n",
    "x_noring = ringing_removal(x, [[50]])\n",
    "utils.plot_signals(t, [x, x_noring], y_names=[\"Original signal with ringing\", \"Cleaned signal\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the algorithm on real MEG data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reuse the output of the step removal algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meg_nostep_noring = ringing_removal(meg_nostep, step_list)\n",
    "\n",
    "utils.plot_signals(range(meg_chan.shape[0]), meg_nostep_noring.T, title=\"After ringing removal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start, end = 343_440, 343_640\n",
    "utils.plot_signals(range(start, end), [meg_nostep[start:end], meg_nostep_noring[start:end]], title=\"Zoom on some ringing artefact\", y_names=[\"After step removal and before ringing removal\", \"After ringing removal\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using the ringing removal algorithm, the signal is cleaner. Data is ready for outlier detection and inpainting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Des truc un peu random à retirer mais pas tout de suite ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_original = np.load('./data/eeg_raw.npy').T\n",
    "# x = x_original\n",
    "# SFREQ = 250\n",
    "# N = x.shape[1]\n",
    "# t = np.arange(x.shape[0]) / SFREQ\n",
    "\n",
    "def plot(x, start=0, end=None):\n",
    "    T, N = x.shape\n",
    "    if end is None:\n",
    "        end = T\n",
    "\n",
    "    fig, axes = plt.subplots(N, sharex=True, figsize=(16, 16))\n",
    "    for n in range(N):\n",
    "        ax = axes[n]\n",
    "        ax.plot(x[start:end, n])\n",
    "    fig.show()\n",
    "\n",
    "# plot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, trend, _, _ = robust_detrend(x, 15, maxiter=100)\n",
    "# plot(trend)\n",
    "# plot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = outlier_detection(x, thres=4, maxiter=20)\n",
    "# x = inpaint(x, w)\n",
    "# plot(x)\n",
    "# print(f\"Outliers per channels (%): {100 * np.sum(~w, axis=0) / t.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = robust_rereferencing(x, w)\n",
    "# plot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(x_original - x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction using dictionary learning\n",
    "Exemple stolen from TP1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single channel data (with steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start, end = 343_300, 343_700\n",
    "std = meg_nostep_noring.std()\n",
    "\n",
    "meg = meg_chan[start:end, :] / std\n",
    "\n",
    "# Step removal + ringing removal + detrending\n",
    "meg_clean = robust_detrend(meg_nostep_noring, 15)[0]\n",
    "meg_clean = meg_clean[start:end, :] / std\n",
    "\n",
    "utils.plot_signals_side_by_side(range(meg.shape[0]), y1=meg.T, y2=meg_clean.T, y_names1=[\"Original signal\"], y_names2=[\"Signal with step removed\"], sharey=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_atoms = 20  # K\n",
    "atom_length = 25  # L\n",
    "penalty = 1. # lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# learning a dictionary and codes\n",
    "pobj, _, d_hat, z_hat, _ = learn_d_z(X=meg.T, n_atoms=n_atoms, n_times_atom=atom_length,\n",
    "    reg=penalty, n_iter=30, n_jobs=4, verbose=1)\n",
    "\n",
    "pobj_clean, _, d_hat_clean, z_hat_clean, _ = learn_d_z(X=meg_clean.T, n_atoms=n_atoms, n_times_atom=atom_length,\n",
    "    reg=penalty, n_iter=30, n_jobs=4, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruction on the original signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction with the dictionary and the sparse codes\n",
    "reconstruction = construct_X(z_hat, d_hat).T\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "tt = np.arange(meg.shape[0])\n",
    "ax.plot(tt, meg, label=\"original\", alpha=0.5)\n",
    "ax.plot(tt, reconstruction, label=\"reconstructed from original\")\n",
    "_ = plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re construction on the signal with step removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction with the dictionary and the sparse codes\n",
    "reconstruction_clean = construct_X(z_hat_clean, d_hat_clean).T\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "tt = np.arange(meg_clean.shape[0])\n",
    "ax.plot(tt, meg_clean, label=\"original with step removed\", alpha=0.5)\n",
    "ax.plot(tt, reconstruction_clean, label=\"reconstructed on signal with step removed\")\n",
    "\n",
    "_ = plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error on both reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Reconstruction MSE (original): {np.mean((meg - reconstruction)**2):.3e}\")\n",
    "print(f\"Reconstruction MSE (step removed): {np.mean((meg_clean - reconstruction_clean)**2):.3e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction (Multi-channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = np.random.permutation(meg_data.shape[1])[:15]\n",
    "meg_data_subset = meg_data[300_000:400_000, channels]\n",
    "meg_clean, step_list = step_removal(meg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meg_clean = ringing_removal(meg_clean, step_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meg_clean = robust_detrend(meg_clean, 15)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n",
      "copy 0.10362100601196289\n",
      "unique 0.02598738670349121\n",
      "unique2 55.537034034729004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part 0.0011820793151855469\n",
      "cat 0.0072422027587890625\n",
      "est 0.8845505714416504\n",
      "reconstruct 9.280398845672607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy 0.4595773220062256\n",
      "unique 0.029469966888427734\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m w \u001b[38;5;241m=\u001b[39m \u001b[43moutlier_detection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeg_clean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthres\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 17\u001b[0m, in \u001b[0;36moutlier_detection\u001b[0;34m(x, thres, maxiter)\u001b[0m\n\u001b[1;32m     13\u001b[0m w \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones_like(x, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m) \u001b[38;5;66;03m# Initially assume there are no outliers\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(maxiter):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Try to reconstruct the data using the inpainting algorithm\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     xbar \u001b[38;5;241m=\u001b[39m \u001b[43minpaint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_valid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Flag high reconstruction errors as outliers\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     d \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(x \u001b[38;5;241m-\u001b[39m xbar)\n",
      "Cell \u001b[0;32mIn[58], line 32\u001b[0m, in \u001b[0;36minpaint\u001b[0;34m(x, w, keep_valid)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munique \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime()\u001b[38;5;241m-\u001b[39mttt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     31\u001b[0m ttt\u001b[38;5;241m=\u001b[39mtime()\n\u001b[0;32m---> 32\u001b[0m pattern, partition \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw_other\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m K \u001b[38;5;241m=\u001b[39m pattern\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munique2 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime()\u001b[38;5;241m-\u001b[39mttt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/arraysetops.py:317\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    314\u001b[0m     uniq \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmoveaxis(uniq, \u001b[38;5;241m0\u001b[39m, axis)\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m uniq\n\u001b[0;32m--> 317\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconsolidated\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m output \u001b[38;5;241m=\u001b[39m (reshape_uniq(output[\u001b[38;5;241m0\u001b[39m]),) \u001b[38;5;241m+\u001b[39m output[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(output)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/arraysetops.py:333\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    330\u001b[0m optional_indices \u001b[38;5;241m=\u001b[39m return_index \u001b[38;5;129;01mor\u001b[39;00m return_inverse\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optional_indices:\n\u001b[0;32m--> 333\u001b[0m     perm \u001b[38;5;241m=\u001b[39m \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margsort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmergesort\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquicksort\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "w = outlier_detection(meg_clean, thres=6, maxiter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meg_clean = inpaint(meg_clean, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meg_clean = robust_rereferencing(meg_clean, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(meg_data_subset)\n",
    "plot(meg_clean)\n",
    "# plot(meg_clean - meg_data_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting real MEG signals (DO NOT RUN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download raw data\n",
    "MEG signals from [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caution, this is a big file \n",
    "# !wget https://figshare.com/ndownloader/files/6509115\n",
    "# !unzip phantom090715_BrainampDBS_20150709_07.ds.zip -d data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import MEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds directory : /home/echristiann/code/robust-detrending-rereferencing-outlier-detection-and-inpainting-for-multichannel-data/data/phantom090715_BrainampDBS_20150709_07.ds\n",
      "    res4 data read.\n",
      "    hc data read.\n",
      "    Separate EEG position data file read.\n",
      "    Quaternion matching (desired vs. transformed):\n",
      "       0.57   76.33    0.00 mm <->    0.57   76.33   -0.00 mm (orig :  -51.86   56.45 -204.73 mm) diff =    0.000 mm\n",
      "      -0.57  -76.33    0.00 mm <->   -0.57  -76.33   -0.00 mm (orig :   59.71  -47.71 -207.65 mm) diff =    0.000 mm\n",
      "      74.18    0.00    0.00 mm <->   74.18    0.00    0.00 mm (orig :   52.72   57.89 -222.24 mm) diff =    0.000 mm\n",
      "    Coordinate transformations established.\n",
      "    Polhemus data for 3 HPI coils added\n",
      "    Device coordinate locations for 3 HPI coils added\n",
      "    Measurement info composed.\n",
      "Finding samples for /home/echristiann/code/robust-detrending-rereferencing-outlier-detection-and-inpainting-for-multichannel-data/data/phantom090715_BrainampDBS_20150709_07.ds/phantom090715_BrainampDBS_20150709_07.meg4: \n",
      "    System clock channel is available, checking which samples are valid.\n",
      "    240 x 2400 = 576000 samples from 339 chs\n",
      "Current compensation grade : 0\n",
      "Reading 0 ... 575999  =      0.000 ...   240.000 secs...\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>July 09, 2015  12:04:00 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>VL</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "            \n",
       "            <td>phantom090715</td>\n",
       "            \n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>3 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>29 Reference Magnetometers, 274 Magnetometers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>2400.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>1200.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "</table>"
      ],
      "text/plain": [
       "<Info | 16 non-empty values\n",
       " bads: []\n",
       " ch_names: BG1-2910, BG2-2910, BG3-2910, BP1-2910, BP2-2910, BP3-2910, ...\n",
       " chs: 29 Reference Magnetometers, 274 Magnetometers\n",
       " comps: 5 items (list)\n",
       " ctf_head_t: CTF/4D/KIT head -> head transform\n",
       " custom_ref_applied: False\n",
       " dev_ctf_t: MEG device -> CTF/4D/KIT head transform\n",
       " dev_head_t: MEG device -> head transform\n",
       " dig: 3 items (3 Cardinal)\n",
       " experimenter: VL\n",
       " highpass: 0.0 Hz\n",
       " hpi_results: 1 item (list)\n",
       " lowpass: 1200.0 Hz\n",
       " meas_date: 2015-07-09 12:04:00 UTC\n",
       " meas_id: 4 items (dict)\n",
       " nchan: 303\n",
       " projs: []\n",
       " sfreq: 2400.0 Hz\n",
       " subject_info: 1 item (dict)\n",
       ">"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "file = \"data/phantom090715_BrainampDBS_20150709_07.ds\"\n",
    "raw = mne.io.read_raw_ctf(file, preload=True)\n",
    "raw = raw.pick_types(meg=True, eeg=False, eog=False)\n",
    "raw.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save data to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw.get_data().T\n",
    "data /= data.std()\n",
    "np.save(\"data/MEG.npy\", np.float32(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Alain de Cheveigné, Dorothée Arzounian,\n",
    "Robust detrending, rereferencing, outlier detection, and inpainting for multichannel data,\n",
    "NeuroImage,\n",
    "Volume 172,\n",
    "2018,\n",
    "Pages 903-912,\n",
    "ISSN 1053-8119,\n",
    "https://doi.org/10.1016/j.neuroimage.2018.01.035.\n",
    "(https://www.sciencedirect.com/science/article/pii/S1053811918300351)\n",
    "\n",
    "[2] Vladimir Litvak. \n",
    "2016. \n",
    "Magnetoencephalography (MEG) recordings from a phantom with Deep Brain Stimulation (DBS) artefacts. \n",
    "DOI:https://doi.org/10.6084/m9.figshare.4042911.v3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
