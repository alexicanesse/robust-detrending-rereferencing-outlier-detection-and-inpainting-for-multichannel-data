{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust detrending, rereferencing, outlier detection, and inpainting, for-multichannel-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of [1] in Python and experiments on real time series.  \n",
    "Esteban Christiann (ENS Paris-Saclay) and Alexi Canesse (ENS de Lyon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, lfilter\n",
    "from meegkit.utils.sig import stmcb # Steiglitz-McBride iteration method for ringing removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 300\n",
    "t, x1, _ = utils.generate_noisy_polynomial(degree=10, noise_level=0.1, num_points=num_points)\n",
    "_, x2, _ = utils.generate_noisy_polynomial(degree=10, noise_level=0.1, num_points=num_points)\n",
    "x3 = x1 + x2 + np.random.normal(scale=0.1, size=[num_points])\n",
    "x = np.stack([x1, x2, x3], axis=1)\n",
    "x_not_corrupted = x.copy()\n",
    "\n",
    "w = np.ones([num_points, 3], dtype=bool)\n",
    "w[50:75, 0] = False\n",
    "w[100:150, 1] = False\n",
    "w[200:220, 2] = False\n",
    "\n",
    "x[~w] = 10\n",
    "\n",
    "utils.plot_signals_side_by_side(t, x.T, x_not_corrupted.T, y_names1=[\"x1\", \"x2\", \"x3\"], y_names2=[\"x1\", \"x2\", \"x3\"], title1=\"Corruped signal\", title2=\"Not corrupted signal\")\n",
    "\n",
    "# Data with steps \n",
    "sigma = 1e-1\n",
    "x_step = np.random.randn(3, num_points) * sigma\n",
    "# Add steps\n",
    "for signal in x_step:\n",
    "    step_locations = utils.generate_random_numbers(np.random.randint(3, 10), 10, num_points - 9, 15)\n",
    "    for step_location in step_locations:\n",
    "        signal[step_location:] += 1. + np.random.random()\n",
    "utils.plot_signals(t, x_step, title=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Robust detrending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_detrend(x, order, w=None, basis='polynomials', thresh=0.5, maxiter=20):\n",
    "     \"\"\"\n",
    "     Robustly removes trend from data.\n",
    "\n",
    "     Parameters:\n",
    "     - x: raw data\n",
    "     - order: order of polynomial or number of sin/cosine pairs\n",
    "     - w: weights\n",
    "     - basis: 'polynomials' [default] or 'sinusoids', or user-provided matrix\n",
    "     - thresh: threshold for outliers [default: .5 sd]\n",
    "     - niter: number of iterations [default: 4]\n",
    "\n",
    "     Returns:\n",
    "     - original - trend: detrended data\n",
    "     - trend: trend\n",
    "     - w: updated weights\n",
    "     - r: basis matrix used\n",
    "     \"\"\"\n",
    "     # Generate basis matrix\n",
    "     if isinstance(basis, np.ndarray):\n",
    "          r = basis\n",
    "     else:\n",
    "          lin = np.linspace(-1, 1, x.shape[0])\n",
    "          if basis == 'polynomials':\n",
    "               r = np.column_stack([lin ** k for k in range(0, order + 1)])\n",
    "          elif basis == 'sinusoids':\n",
    "               r = np.column_stack([np.sin(2 * np.pi * k * lin / 2) for k in range(0, order + 1)] +\n",
    "                                   [np.cos(2 * np.pi * k * lin / 2) for k in range(0, order + 1)])\n",
    "          else:\n",
    "               raise ValueError(\"Invalid basis type\")\n",
    "\n",
    "     # Initialize weights if not provided\n",
    "     if w is None:\n",
    "          w = np.ones_like(x, dtype=bool)\n",
    "\n",
    "     \n",
    "     # If the data is multichannel, the algorithm is applied to each channel independently \n",
    "     trend = x.copy()\n",
    "     original = x.copy()\n",
    "     if len(trend.shape) == 1:\n",
    "          trend = trend[:, np.newaxis]\n",
    "          original = original[:, np.newaxis]\n",
    "          w = w[:, np.newaxis]\n",
    "     \n",
    "     for dim in range(trend.shape[1]):\n",
    "          for _ in range(maxiter):\n",
    "               # Fit to basis\n",
    "               coefficients = np.linalg.lstsq(r[w[:, dim], :], original[w[:, dim], dim], rcond=None)[0]\n",
    "               trend[:, dim] = r @ coefficients\n",
    "\n",
    "               # Update weights\n",
    "               d = np.abs(trend[:, dim] - original[:, dim])\n",
    "\n",
    "               new_w = d < thresh * np.std(d)\n",
    "               if (new_w == w[:, dim]).all():\n",
    "                    # Algorithm converged, early stopping\n",
    "                    break\n",
    "               w[:, dim] = new_w\n",
    "\n",
    "\n",
    "     return original - trend, trend, w, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detrended_x1, trend_x1, weights_x1, _ = robust_detrend(x[:, 0], 10, thresh=1)\n",
    "utils.plot_signals(t, [x[:, 0], detrended_x1[:, 0], weights_x1, trend_x1], y_names=[\"signal\", \"detrended\", \"weights\", \"fit\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inpainting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inpaint(x, w, keep_valid=True):\n",
    "    \"\"\"\n",
    "    Reconstruct data if corrupted samples are known\n",
    "\n",
    "    Parameters:\n",
    "    - x: Nchannels x Nsamples raw data\n",
    "    - w: Nchannels x Nsamples bool matrix indicating corruptions\n",
    "    - keep_valid: set to true to reconstruct only corrupted samples\n",
    "\n",
    "    Returns:\n",
    "    - new_x: reconstructed data\n",
    "    \"\"\"\n",
    "    if w is None:\n",
    "        w = np.ones_like(x, dtype=bool)\n",
    "\n",
    "    N = x.shape[1] # Number of channels\n",
    "    new_x = x.copy()\n",
    "\n",
    "    for n in range(N):\n",
    "        w_other = w.copy()\n",
    "        w_other[:, n] = False\n",
    "\n",
    "        # Partition the time axis using the state of other channels\n",
    "        pattern, partition = np.unique(w_other, axis=0, return_inverse=True)\n",
    "        K = pattern.shape[0]\n",
    "\n",
    "        for k in range(K):\n",
    "            T_k = partition == k\n",
    "            Tprime_k = np.logical_and(w[:, n], T_k) # Timestamps we use to estimate the projection\n",
    "            \n",
    "            Tinpaint = np.logical_and(~w[:, n], T_k) # Timestamps to reconstruct\n",
    "            if not keep_valid:\n",
    "                Tinpaint = T_k\n",
    "\n",
    "            if Tinpaint.any():\n",
    "                xn = x[:, n]\n",
    "                xother = x[:, pattern[k]]\n",
    "                xother = np.concatenate([xother, np.ones_like(xn)[:, None]], axis=1)\n",
    "\n",
    "                # Estimate the coefficients and reconstuct the data\n",
    "                coefs = np.linalg.lstsq(xother[Tprime_k], xn[Tprime_k], rcond=None)[0]\n",
    "                new_x[Tinpaint, n] = xother[Tinpaint] @ coefs\n",
    "\n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inpaint = inpaint(x, w)\n",
    "\n",
    "utils.plot_signals_side_by_side(t, x_inpaint.T, x.T, title1=\"Inpainted\", title2=\"Original\")\n",
    "\n",
    "to_plot = np.concatenate([x_inpaint, x_inpaint[:, [0]] + x_inpaint[:, [1]]], axis=1)\n",
    "utils.plot_signals_side_by_side(t, to_plot.T, [x_inpaint[:, 0] + x_inpaint[:, 1] - x_not_corrupted[:,2], x[:,2]], y_names1=[\"x1\", \"x2\", \"x3\", \"x1 + x2\"], y_names2=[\"Difference between not corrupted and reconstructed\", \"Corrupted\"], title1=\"Reconstruction of x3 using inpainted signals\", title2=\"Reconstruction of x3 using inpainted signals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_detection(x, thres=2., maxiter=20):\n",
    "    \"\"\"\n",
    "    Flag outliers using the inpaint algorithm\n",
    "\n",
    "    Parameters:\n",
    "    - x: Nchannels x Nsamples raw data\n",
    "    - thres: threshold for outlier detection (default: 2 stddev)\n",
    "    - maxiter: maximum number of iterations\n",
    "\n",
    "    Returns:\n",
    "    - w: Nchannels x Nsamples bool matrix where False indicates an outlier\n",
    "    \"\"\"\n",
    "    w = np.ones_like(x, dtype=bool) # Initially assume there are no outliers\n",
    "\n",
    "    for _ in range(maxiter):\n",
    "        # Try to reconstruct the data using the inpainting algorithm\n",
    "        xbar = inpaint(x, w, keep_valid=False)\n",
    "\n",
    "        # Flag high reconstruction errors as outliers\n",
    "        d = np.abs(x - xbar)\n",
    "        new_w = ~(d > thres * d.std(axis=0, keepdims=True))\n",
    "        \n",
    "        # Early stopping if the algorithm has converged\n",
    "        if (w == new_w).all():\n",
    "            return w\n",
    "        w = new_w\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_w = outlier_detection(x)\n",
    "utils.plot_signals_side_by_side(t, x.T, estimated_w.T, title1=\"Signal\", title2=\"estimated weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Robust Rereferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_rereferencing(x, w=None):\n",
    "    \"\"\"\n",
    "    Perform robust referencing on the input signal.\n",
    "\n",
    "    Parameters:\n",
    "    - x (numpy.ndarray): Input signal.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: Robustly referenced signal.\n",
    "    \"\"\"\n",
    "    if w is None:\n",
    "        w = outlier_detection(x)\n",
    "    robust_mean = np.mean(x, where=w)\n",
    "    return x - robust_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rereferenced_x = robust_rereferencing(x)\n",
    "utils.plot_signals_side_by_side(t, rereferenced_x.T, rereferenced_x.T - (x_not_corrupted.T - np.mean(x_not_corrupted)), title1=\"Rereferenced\", title2=\"Difference with non corrupted rereferenced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Step Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_steps(x, thresh, guard, depth):\n",
    "    \"\"\"\n",
    "    Find step glitch\n",
    "\n",
    "    Parameters:\n",
    "    - x (numpy.ndarray): Data to clean.\n",
    "    - thresh (float): Threshold\n",
    "    - guard (int): Minimum duration of stable interval in samples .\n",
    "    - depth (int): Recursion depth, determines the number of steps.\n",
    "\n",
    "    Returns:\n",
    "    - stepList (list): Indices of steps.\n",
    "    \"\"\"\n",
    "    if depth == 0 or len(x) < 2 * guard:\n",
    "        return []\n",
    "\n",
    "    T = x.shape[0] # x is a single channel here\n",
    "    M = np.array([np.array([np.mean(x[t_low:t_high + 1]) for t_high in range(t_low, T)]) for t_low in range(T)], dtype=object)\n",
    "    V = np.array([np.array([np.sum(np.square(x[t_low:t_high + 1] - M[t_low][t_high - t_low])) for t_high in range(t_low, T)]) for t_low in range(T)], dtype=object)\n",
    "\n",
    "    t0 = np.nanargmin([V[0][t] + V[t][-1] for t in range(guard, T - guard)])\n",
    "    steps = [guard + t0]\n",
    "\n",
    "    # Check if the step is relevent \n",
    "    if (V[0][t0] + V[t0][-1])/V[0][-1] > thresh:\n",
    "        return []\n",
    "\n",
    "    if depth and steps:\n",
    "        steps_left = find_steps(x[:steps[0]], thresh=thresh, guard=guard, depth=depth-1)\n",
    "        # Add an offset because x[steps[0] + 1] becomes index 0\n",
    "        steps_right = steps[0] + 1 + find_steps(x[steps[0]+1:], thresh=thresh, guard=guard, depth=depth-1)\n",
    "        steps = np.concatenate((steps_left, steps, steps_right))\n",
    "\n",
    "    return steps.astype(int)\n",
    "\n",
    "def step_removal(x, thresh=0.5, guard=5, depth=5):\n",
    "    \"\"\"\n",
    "    Remove step glitch\n",
    "    \n",
    "    Parameters:\n",
    "    - x (numpy.ndarray): Data to clean (time * channels).\n",
    "    - thresh (float): Threshold (default: 0.7).\n",
    "    - guard (int): Minimum duration of stable interval in samples (default: 5).\n",
    "    - depth (int): Recursion depth (default: 5), determines the number of steps.\n",
    "\n",
    "    Returns:\n",
    "    - y (numpy.ndarray): Step-removed data.\n",
    "    - stepList (list): Indices of steps.\n",
    "    \"\"\"\n",
    "\n",
    "    y = x.copy()\n",
    "\n",
    "    all_stepList = []\n",
    "    for chan in range(x.shape[1]):\n",
    "        # Find step indices\n",
    "        stepList = find_steps(x[:, chan], thresh=thresh, guard=guard, depth=depth)\n",
    "\n",
    "        if len(stepList):\n",
    "            stepList = [0] + list(stepList) + [x.shape[0]]\n",
    "            for split in range(1, len(stepList) - 1):\n",
    "                y1 = y[stepList[split - 1] + 1 : stepList[split] - 1, chan]  # plateau before\n",
    "                y2 = y[stepList[split] + 1 : stepList[split + 1] - 1, chan]  # plateau after\n",
    "                step = np.mean(y2) - np.mean(y1)\n",
    "                y[stepList[split] + 1:, chan] -= step\n",
    "\n",
    "        all_stepList.extend(stepList[1:-1])\n",
    "\n",
    "    return y, np.array(all_stepList).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_step_removed, stepList = step_removal(x_step.T)\n",
    "utils.plot_signals(t, [x_step.T, x_step_removed], y_names=[\"Step signal\", \"de-stepped signal\"], y_lines=[t[step] for step in stepList])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ringing removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ringing_removal(x, step_list):\n",
    "    \"\"\"\n",
    "    Reduce ringing effect caused by the antialiasing filter response to steps\n",
    "\n",
    "    Paramters:\n",
    "    - x: (Nsamples, Nchannels) data matrix\n",
    "    - step_list: list of step indexes (can be found with step removal algorithm)\n",
    "\n",
    "    Return:\n",
    "    - new_x: cleaned data\n",
    "    \"\"\"\n",
    "    N = x.shape[1]\n",
    "    n_num, n_den = 8, 8\n",
    "    n_samples = 100\n",
    "\n",
    "    new_x = x.copy()\n",
    "    for step in step_list:\n",
    "        for n in range(N):\n",
    "            ringing = x[step : step+n_samples, n]\n",
    "            ringing = np.concatenate([ringing, np.zeros_like(ringing)])\n",
    "            b, a = stmcb(ringing, q=n_num, p=n_den, niter=10)\n",
    "\n",
    "            impulse = np.arange(n_samples) == 0\n",
    "            model = lfilter(b, a, impulse)\n",
    "            new_x[step : step+n_samples, n] -= model\n",
    "\n",
    "    return new_x\n",
    "\n",
    "\n",
    "[b, a] = butter(6, 0.2)\n",
    "x = np.arange(300) == 0\n",
    "x = lfilter(b, a, x) * 100\n",
    "x = np.roll(x, 50) + np.random.normal(size=300)\n",
    "x = x[:, None]\n",
    "t = np.linspace(0, 1, x.shape[0])\n",
    "\n",
    "new_x = ringing_removal(x, [50])\n",
    "utils.plot_signals(t, [x, new_x], y_names=[\"Original signal with ringing\", \"Cleaned signal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_original = np.load('./data/eeg_raw.npy').T\n",
    "x = x_original\n",
    "SFREQ = 250\n",
    "N = x.shape[1]\n",
    "t = np.arange(x.shape[0]) / SFREQ\n",
    "\n",
    "def plot(x, start=0, end=None):\n",
    "    if end is None:\n",
    "        end = x.shape[0]\n",
    "\n",
    "    fig, axes = plt.subplots(N, sharex=True, figsize=(12, 8))\n",
    "    for n in range(N):\n",
    "        ax = axes[n]\n",
    "        ax.plot(t[start:end], x[start:end, n])\n",
    "    fig.show()\n",
    "\n",
    "plot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, trend, _, _ = robust_detrend(x, 15, maxiter=100)\n",
    "plot(trend)\n",
    "plot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = outlier_detection(x, thres=4, maxiter=30)\n",
    "x = inpaint(x, w)\n",
    "plot(x)\n",
    "print(f\"Outliers per channels (%): {100 * np.sum(~w, axis=0) / t.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = robust_rereferencing(x, w)\n",
    "plot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(x_original - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.tsa.api import VAR, AutoReg, VARMAX\n",
    "\n",
    "data = np.float32(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VARMAX(data, order=(2, 0)).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_true = []\n",
    "x_model = []\n",
    "for i in range(5*SFREQ, data.shape[0] - 5*SFREQ, SFREQ):\n",
    "    x_true.append(data[i:i+SFREQ])\n",
    "    x_model.append(model.predict(start=i, end=i+SFREQ-1))\n",
    "\n",
    "    if i == 10*SFREQ:\n",
    "        plot(x_model[-1])\n",
    "        plot(x_true[-1])\n",
    "        plot(x_model[-1] - x_true[-1])\n",
    "    \n",
    "x_true = np.concatenate(x_true, axis=0)\n",
    "x_model = np.concatenate(x_model, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.mean(  np.abs(x_true - x_model)  )\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Alain de Cheveigné, Dorothée Arzounian,\n",
    "Robust detrending, rereferencing, outlier detection, and inpainting for multichannel data,\n",
    "NeuroImage,\n",
    "Volume 172,\n",
    "2018,\n",
    "Pages 903-912,\n",
    "ISSN 1053-8119,\n",
    "https://doi.org/10.1016/j.neuroimage.2018.01.035.\n",
    "(https://www.sciencedirect.com/science/article/pii/S1053811918300351)\n",
    "Abstract: Electroencephalography (EEG), magnetoencephalography (MEG) and related techniques are prone to glitches, slow drift, steps, etc., that contaminate the data and interfere with the analysis and interpretation. These artifacts are usually addressed in a preprocessing phase that attempts to remove them or minimize their impact. This paper offers a set of useful techniques for this purpose: robust detrending, robust rereferencing, outlier detection, data interpolation (inpainting), step removal, and filter ringing artifact removal. These techniques provide a less wasteful alternative to discarding corrupted trials or channels, and they are relatively immune to artifacts that disrupt alternative approaches such as filtering. Robust detrending allows slow drifts and common mode signals to be factored out while avoiding the deleterious effects of glitches. Robust rereferencing reduces the impact of artifacts on the reference. Inpainting allows corrupt data to be interpolated from intact parts based on the correlation structure estimated over the intact parts. Outlier detection allows the corrupt parts to be identified. Step removal fixes the high-amplitude flux jump artifacts that are common with some MEG systems. Ringing removal allows the ringing response of the antialiasing filter to glitches (steps, pulses) to be suppressed. The performance of the methods is illustrated and evaluated using synthetic data and data from real EEG and MEG systems. These methods, which are mainly automatic and require little tuning, can greatly improve the quality of the data.\n",
    "Keywords: EEG; MEG; LFP; ECoG; Artifact; ICA; CSP; DSS; SNS; CCA; Sensor noise; Detrending; Weighted regression; Robust statistics\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
